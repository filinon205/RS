{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# from src.metrics import precision_at_k, recall_at_k\n",
    "from src.metrics import precision_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disabling warnings entirely\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/retail_train.csv')\n",
    "\n",
    "data = data.sample(2000, random_state = 2021) # ограничение по записям 2000\n",
    "\n",
    "\n",
    "item_features = pd.read_csv('../raw_data/product.csv')\n",
    "user_features = pd.read_csv('../raw_data/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filter items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "take_n_popular = 1000 # ограничение на 1000\n",
    "\n",
    "data_train_filtered = prefilter_items(data_train, take_n_popular=take_n_popular, item_features=item_features)\n",
    "\n",
    "n_items_after = data_train_filtered['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prepare csr TRAIN matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_matrix = pd.pivot_table(data_train, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "train_user_item_matrix = train_user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат sparse matrix\n",
    "sparse_train_user_item = csr_matrix(train_user_item_matrix).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prepare csr TEST matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "\n",
    "test_user_item_matrix = pd.pivot_table(data_test, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "sparse_test_user_item = csr_matrix(test_user_item_matrix).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_itemid, id_to_userid, itemid_to_id, userid_to_id =\\\n",
    "MainRecommender.prepare_dicts(train_user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare user and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = pd.DataFrame(train_user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat = pd.DataFrame(train_user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the LifgtFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features=csr_matrix(user_feat_lightfm.values).tocsr()\n",
    "item_features=csr_matrix(item_feat_lightfm.values).tocsr()\n",
    "\n",
    "sample_weight=coo_matrix(train_user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=40,\n",
    "#                 loss='bpr',\n",
    "                loss='warp',\n",
    "                learning_rate=0.05, \n",
    "                item_alpha=0.1,\n",
    "                user_alpha=0.1, \n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit((sparse_train_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=sample_weight,\n",
    "          user_features=user_features,\n",
    "          item_features=item_features,\n",
    "          epochs=15, \n",
    "          num_threads=4,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emb = model.get_user_representations(features=csr_matrix(user_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_emb = model.get_item_representations(features=csr_matrix(item_feat_lightfm.values).tocsr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model,\n",
    "                                 sparse_train_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_item_ids = np.array([1, 2, 3, 200, 1200])\n",
    "\n",
    "predictions = model.predict(user_ids=0,\n",
    "                            item_ids=test_item_ids,\n",
    "                            user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                            item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                            num_threads=4)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_precision = precision_at_k(model, \n",
    "                                sparse_test_user_item, \n",
    "                                user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                k=5).mean()\n",
    "\n",
    "test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Прочитать статьи про BPR, WARP loss, learning-to-rank*\n",
    "\n",
    "2) Сделать грид серч текущей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def dict_configs(d):\n",
    "    for vcomb in product(*d.values()):\n",
    "        yield dict(zip(d.keys(), vcomb))\n",
    "\n",
    "param_grid = {\n",
    "            \"no_components\": np.arange(25,55,25),\n",
    "#             \"learning_schedule\": [\"adagrad\"], #\"adadelta\"\n",
    "            \"loss\": [\"warp\"], #\"bpr\"\n",
    "            \"learning_rate\": np.arange(.01,.1,.05),\n",
    "            \"item_alpha\": np.arange (.01,.1,.05),\n",
    "            \"user_alpha\": np.arange (.01,.1,.05),\n",
    "#             \"max_sampled\": np.arange(1,101,25),\n",
    "            \"num_epochs\": np.arange(10,70,30),\n",
    "            \"random_state\":[42],\n",
    "        }\n",
    "\n",
    "def grid_search(sparce_matrix_train, \n",
    "                  test, \n",
    "                  sample_weight, \n",
    "                  user_features,\n",
    "                  item_features,\n",
    "                num_threads=8):\n",
    "\n",
    "    for hyperparams in dict_configs(param_grid):\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "       \n",
    "        model = LightFM(**hyperparams)\n",
    "        \n",
    "        model.fit(sparse_train_user_item,\n",
    "                  sample_weight=sample_weight,\n",
    "                  user_features=user_features,\n",
    "                  item_features=item_features,\n",
    "                  epochs=num_epochs, \n",
    "                  num_threads=num_threads,\n",
    "                  verbose=False)\n",
    "\n",
    "        score = precision_at_k(model,\n",
    "                               test,\n",
    "                               user_features=user_features,\n",
    "                               item_features=item_features,\n",
    "                               k=5).mean()\n",
    "\n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "\n",
    "        yield (score, hyperparams, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.datasets import fetch_movielens\n",
    "(score, hyperparams, model) = max(grid_search(sparse_train_user_item, \n",
    "                                                sparse_test_user_item,\n",
    "                                                sample_weight=sample_weight,\n",
    "                                                user_features=user_features,\n",
    "                                                item_features=item_features,\n",
    "                                             ),\n",
    "                                  key=lambda x: x[0])\n",
    "\n",
    "print(\"Best score {} at {}\".format(score, hyperparams))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
